{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Oligopool Calculator` in Action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author** Ayaan Hossain\n",
    "\n",
    "**Updated** January 24, 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `jupyter` notebook will demonstrate the usage of `Oligopool Calculator` and describe its many functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Notebook Setup](#Notebook-Setup)\n",
    "* [What is Oligopool Calculator?](#What-is-Oligopool-Calculator?)\n",
    "* [Design Mode Walkthrough](#Design-Mode-Walkthrough)\n",
    "    * [Simulating the problem](#Simulating-the-problem)\n",
    "    * [Reviewing constraints and formulating gameplan](#Reviewing-constraints-and-formulating-gameplan)\n",
    "    * [Primer design review](#Primer-design-review)\n",
    "    * [Storing the plasmid background](#Storing-the-plasmid-background)\n",
    "    * [Designing the triple-primer system](#Designing-the-triple-primer-system)\n",
    "    * [Generating orthogonal barcodes](#Generating-orthogonal-barcodes)\n",
    "    * [Adding neutral motifs, spacers, and finalizing library](#Adding-neutral-motifs,-spacers,-and-finalizing-library)\n",
    "    * [Splitting and padding oligos](#Splitting-and-padding-oligos)\n",
    "* [Analysis Mode Walkthrough](#Analysis-Mode-Walkthrough)\n",
    "    * [Indexing the barcodes and associated variants](#Indexing-the-barcodes-and-associated-variants)\n",
    "    * [Packing the NGS reads for quantification](#Packing-the-NGS-reads-for-quantification)\n",
    "    * [Overview of counting methods](#Overview-of-counting-methods)\n",
    "    * [Association counting of variants and barcodes](#Association-counting-of-variants-and-barcodes)\n",
    "    * [Combinatorial barcode counting with callback](#Combinatorial-barcode-counting-with-callback)\n",
    "* [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to have `Oligopool Calculator` installed to proceed. You can install it by uncommenting and executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install oligopool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `oligopool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oligopool as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need `numpy` to do some math, and we will use `pandas` as our data container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need `matplotlib`/`seaborn` for plotting, and `pprint` for pretty printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will need `multiprocessing` `Manager` to create a shared dictionary for demonstrating synchronized callback memory during counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're all set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Oligopool Calculator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oligonucleotide pools (oligopools) have revolutionized synthetic biology by enabling large-scale, cost-effective synthesis of hundreds of thousands of unique, short single-stranded DNA sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These oligopools facilitate the creation and study of various biological components, including de novo promoters, ribozymes, protein scaffolds, and CRISPR libraries. Massively parallel reporter assays (MPRAs) are utilized to clone and assess the functionality of these variants using high-throughput next-generation sequencing (NGS), which can generate billions of short reads per experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking ahead, advancements are expected in the number and length of oligos, NGS throughput, and reductions in manufacturing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Oligopool Calculator Workflow](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/workflow.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Oligopool Calculator` is a comprehensive tool for designing and analyzing large-scale oligonucleotide pools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **(a)** `Design Mode`, the algorithms optimize various elements of the oligopool, including barcodes, primers, spacers, and degenerate motifs. It ensures that these components are maximally distinct, non-repetitive, and free from undesired sequences or structures. The tool also enables the splitting of long oligos into shorter fragments with optimized overlaps for downstream assembly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **(b)** `Analysis Mode` of `Oligopool Calculator` facilitates the processing of next-generation sequencing (NGS) data derived from barcoded amplicons. This mode allows for efficient mapping of variants and their associated barcodes, producing count matrices for quantitative assessment of variant functionality. Two types of counting operations are supported: Association Counting for assessing synthesis accuracy, and Combinatorial Counting for analyzing multiple barcode combinations from sequencing reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall `Oligopool Calculator` provides synthetic biologists with a unified platform for oligopool design and characterization, addressing the need for a standardized approach across different projects and labs. This tool eliminates the need for reinventing design scripts or using suboptimal strategies, making it particularly valuable for designing and analyzing pools containing millions of defined variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Mode Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to design and test a library of 6,232 ribozyme variants based on the following architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ribozyme Library Architecture](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/architecture-ribozyme.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To characterize the activity of our library in _E. coli_, we adopt a two-barcode strategy. Because ribozymes are self-cleaving, the two barcodes (BC1 and BC2), placed before and after the core variant, are separated after catalysis. This lets us quantify cleavage by counting the ratio of “separated” to “unseparated” reads.\n",
    "\n",
    "When using multiple barcode columns, it can also be useful to enforce *cross-set* separation (e.g., ensure BC2 barcodes are also far from the BC1 barcode set), which we will demonstrate later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of demonstration, let us first generate a random library of 59-73 mers (designing exact ribozymes is beyond the scope here) and assume that the library will be cloned into a 5 kb plasmid backbone for characterization, which we will also generate randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = ['A', 'T', 'G', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ribozymes = []\n",
    "while len(ribozymes) < 6232:\n",
    "    variant = ''.join(rng.choice(dna, size=rng.integers(low=59, high=74)))\n",
    "    if 'GAATTC' in variant or 'GACGTC' in variant or 'GGTCTC' in variant or 'GAGACC' in variant:\n",
    "        # Skipping if random variant has EcoRI, AatII, or BsaI motif\n",
    "        continue\n",
    "    ribozymes.append(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,5))\n",
    "sns.histplot([len(x) for x in ribozymes], binwidth=1)\n",
    "ax.set_xticks(np.arange(59,74))\n",
    "ax.set_xlabel('Ribozyme Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ribozymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasmid = ''.join(rng.choice(dna) for _ in range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plasmid) # 5 kbp long plasmid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviewing constraints and formulating gameplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated 6,232 simulated candidates between 59 to 73 bp in length, and a plasmid of length 5 kbp. We want to use `EcoRI` and `AatII` as our restriction sites as part of the characterization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `Oligopool Calculator` to design the following.\n",
    "* Three primers, each 20bp in length,\n",
    "* The prefix and suffix barcodes each 11bp in length, and\n",
    "* Variable length spacers ranging from 3 to 17bp to pad the oligos to 170bp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As constraints, we aim to have the following.\n",
    "* The primers should not have off-target binding within the library or to the backbone,\n",
    "* Addition of primers, barcodes or spacers should not contain `EcoRI`, `AatII`, or `BsaI` (Type IIS for padding) motifs or introduce them at the edges, and\n",
    "* The barcodes should all have at least 3 mismatches separating each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other realistic constraints, such as exclusion of all palindomic hexamers, or polymeric runs such as `'AAAAA'`, ..., `'CCCCC'` may be included as they were in the original projects, but we will skip those for this demonstration. In reality, constaints will depend on the design project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful habit in Design Mode is to measure and QC as we go:\n",
    "\n",
    "- `lenstat` is a fast length ruler: it reports per-element and per-oligo lengths and remaining free space under an `oligo_length_limit` (it does not modify the input DataFrame).\n",
    "- `verify` is a broader QC pass (often right before synthesis): it summarizes sequence vs metadata columns, flags degenerate/mixed columns, and checks length overflow + excluded motif emergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we begin? By asking `help` from `Oligopool Calculator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the help, we will need to primarily use the `barcode`, `primer`, and `spacer` modules to add the library elements.\n",
    "\n",
    "These element modules (`barcode`, `primer`, `motif`, `spacer`) also support **Patch Mode** (`patch_mode=True`), which is designed for iterative workflows:\n",
    "\n",
    "- If you **append new rows** to an already-designed pool (e.g., you already ordered BC1/primers, then later add new variants), Patch Mode fills only the missing values in an existing output column and leaves existing designs untouched.\n",
    "- This makes **vertical expansion** safe: you can extend a pool without redesigning (and potentially changing) existing barcodes/primers/anchors/spacers.\n",
    "\n",
    "In Patch Mode, missing values (e.g., `None`/NaN/empty/`'-'`) are treated as design targets; existing values are sanity-checked (DNA + expected length) but are not re-designed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer design review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, primers are the most constrained elements in an oligopool library because they have to follow a desired sequence constraint (such as `5'-GC` clamps), be free of inhibitory structures, be very specific to the library and have minimal off-targeting to background. We recommend designing primers as early as possible, but after all other elements in the library have been finalized, such as any motifs (discussed later in this notebook).\n",
    "\n",
    "For multiplexed libraries, you can assign per-oligo set labels via `oligo_sets` to design primers independently for each set while ensuring cross-set compatibility. If a paired primer column is supplied, the paired primer is interpreted per set so that each group remains internally matched.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Primer Design](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/primer.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any step in the process if we get stuck, `Oligopool Calculator` will tell us what is preventing it from succeeding and we can relax or modify our constraints accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we design primers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.primer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things should stand out here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, primer design involves consideration of background sequences to minimize off-target amplification, such as from the plasmid we set up. We will need to compute this information prior to primer design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, primer design involves consideration of pairing information. If we only had two primers (one forward and one reverse) the order of their design would not matter. But in our problem, there are two forward primers (pink and orange) both of which are coupled to a single reverse primer (yellow). It will be important to design them in the right order, as we will discuss shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first solve the background problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the plasmid background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Oligopool Calculator` makes it easy to define a background for primer design via the `background` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you want to modify the background post-hoc, or want to define your background using a custom strategy, directly use the `vectorDB` module, which behaves like a dictionary. For details use `help(op.vectorDB)`. The `background` module just wraps around it and offers an one-time use simple interface to `vectorDB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_directory = 'demo.oligopool.background' # Path to store our background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the background if one exists already, for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf $background_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the `background` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_stats = op.background(\n",
    "    input_data=plasmid,\n",
    "    maximum_repeat_length=8,\n",
    "    output_directory=background_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(background_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now stored the background, and are ready to design the three primers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: All `Oligopool Calculator` functions should return a pipeline statistics dictionary recapitulating the output from the last step performed in the function. If the operation completed successfully, the `status` key will be marked as `True` and `basis` will be marked as `'solved'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing the triple-primer system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All `Design Mode` input and output is mediated through a `pandas` `DataFrame` to facilitate carefully piplined designs. Let us store the variant candidates in a dataframe and start the design process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ID': [f'ribozyme_{x+1:04d}' for x in range(len(ribozymes))],\n",
    "    'EcoRI': 'GAATTC',\n",
    "    'Variant':ribozymes,\n",
    "    'AatII': 'GACGTC',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the primers are coupled, an optimal solution here is to design the innermost (pink) forward primer first, and then design the reverse primer (yellow), followed by designing the outermost (orange) forward primer. This allows all three primers to be compatible with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternate solution would involve designing the (yellow) reverse primer first, and then designing the two forward primers successively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we designed the (yellow) reverse primer at the end, it would be difficult to ensure that it is compatible with both forward primers simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? op.primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, stats = op.primer(\n",
    "    input_data=df,\n",
    "    oligo_length_limit=170,                           # Must not exceed 170bp at any stage\n",
    "    primer_sequence_constraint='SS' + 'N'*18,         # Manually install 5p GC clamp if required\n",
    "    primer_type='forward',                            # Forward primer design\n",
    "    primer_column='PinkForwardPrimer',                # Store designs in 'PinkForwardPrimer' column\n",
    "    left_context_column='Variant',                    # Next to 'Variant' column\n",
    "    right_context_column='AatII',                     # Before 'AatII' column\n",
    "    paired_primer_column=None,                        # No paired primer yet\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'],  # Exclude EcoRI, AatII, BsaI motifs\n",
    "    minimum_melting_temperature=53,                   # Tm = 53°C at least\n",
    "    maximum_melting_temperature=55,                   # Tm = 55°C at most\n",
    "    maximum_repeat_length=10,                         # No more than 10-mer repeats allowed\n",
    "    background_directory=background_directory,        # As setup before\n",
    "    output_file=None)                                 # In-memory return, no CSV written here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The designed primer is predicted to be free from hairpin structures with low homodimer probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now design the two remaining primers in silent mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = op.primer(\n",
    "    input_data=df,                                   # Updated DataFrame along pipeline chain\n",
    "    oligo_length_limit=170,\n",
    "    primer_sequence_constraint='N'*18 + 'WW',        # Manually install 3p AT clamp if needed\n",
    "    primer_type='reverse',                           # Reverse primer design\n",
    "    primer_column='YellowReversePrimer',             # Store designs in 'YellowReversePrimer' column\n",
    "    left_context_column='PinkForwardPrimer',         # Next to 'PinkForwardPrimer' column\n",
    "    right_context_column='AatII',                    # Before 'AatII' column\n",
    "    paired_primer_column='PinkForwardPrimer',        # Yellow reverse primer paired with pink forward primer\n",
    "    minimum_melting_temperature=53,\n",
    "    maximum_melting_temperature=55,\n",
    "    maximum_repeat_length=10,\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'],  # Exclude EcoRI, AatII, BsaI motifs\n",
    "    background_directory=background_directory,\n",
    "    verbose=False)                               # Silent Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = op.primer(\n",
    "    input_data=df,                                    # Updated DataFrame along pipeline chain\n",
    "    oligo_length_limit=170,\n",
    "    primer_sequence_constraint='N'*20,\n",
    "    primer_type='forward',                            # Forward primer design\n",
    "    primer_column='OrangeForwardPrimer',              # Store designs in 'OrangeForwardPrimer' column\n",
    "    left_context_column='EcoRI',                      # Next to 'EcoRI' column\n",
    "    right_context_column='Variant',                   # Before 'Variant' column\n",
    "    paired_primer_column='YellowReversePrimer',       # Orange forward primer paired with yellow reverse primer\n",
    "    minimum_melting_temperature=53,\n",
    "    maximum_melting_temperature=55,\n",
    "    maximum_repeat_length=10,\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'],  # Exclude EcoRI, AatII, BsaI motifs\n",
    "    background_directory=background_directory,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our primers are installed. Barcodes up next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before that, since we're done with the background let's drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(op.vectorDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.vectorDB(background_directory, maximum_repeat_length=None).drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating orthogonal barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barcodes are critical elements that help identify each variant uniquely, especially when the core oligo variants are similar to each other. `Oligopool Calculator` maximizes barcode distinguishability which is useful, for example, when the library is exploring all single substitutions to a template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Barcode Design](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/barcode.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.barcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike primers which need to satisfy global constraints (a hard problem), barcodes are optimized contextually. So, barcodes may be designed after all the primers have been installed. However, the pairwise Hamming distance requirement coupled with other constraints makes it difficult to judge ahead of time if there are enough barcodes possible for a given library with desired constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us design BC1 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = op.barcode(\n",
    "    input_data=df,\n",
    "    oligo_length_limit=170,\n",
    "    barcode_length=11,\n",
    "    minimum_hamming_distance=3,  # As defined by our goal\n",
    "    maximum_repeat_length=6,     # To prevent internal hairpins, say\n",
    "    barcode_column='BC1',\n",
    "    barcode_type='spectrum',     # Spectrum optimized barcodes\n",
    "    left_context_column='OrangeForwardPrimer',\n",
    "    right_context_column='Variant',\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'])  # Exclude EcoRI, AatII, BsaI motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the barcodes have at least 4 mismatches separating them, and all of them are at least 3 mismatches apart as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's add BC2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-barcode sets (optional):** When designing multiple barcode columns (BC1, BC2, ...), you may want each new barcode set to be separated not only within itself (`minimum_hamming_distance`), but also from existing barcode sets.\n",
    "\n",
    "`cross_barcode_columns` + `minimum_cross_distance` enforce a *global* cross-set Hamming distance between each newly designed barcode and the union of barcodes in the specified column(s) (not a per-row pairing constraint).\n",
    "\n",
    "Below, BC2 is designed to be ≥3 mismatches away from every BC1 sequence. For a third barcode, you could use `cross_barcode_columns=['BC1','BC2']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = op.barcode(\n",
    "    input_data=df,\n",
    "    oligo_length_limit=170,\n",
    "    barcode_length=11,\n",
    "    minimum_hamming_distance=3,\n",
    "    maximum_repeat_length=6,\n",
    "    barcode_column='BC2',\n",
    "    barcode_type='spectrum',     # Spectrum optimized barcodes\n",
    "    left_context_column='PinkForwardPrimer',\n",
    "    right_context_column='YellowReversePrimer',\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'],  # Exclude EcoRI, AatII, BsaI motifs\n",
    "    cross_barcode_columns=['BC1'],\n",
    "    minimum_cross_distance=3,\n",
    "    verbose=False)  # Silent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barcodes are done! The only thing left to design are the spacers so that all oligos have the same length of 170 bp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before designing spacers, we first measure how much length budget is left. The `lenstat` module is a quick ruler: it reports per-element lengths and remaining free space, without modifying the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(op.lenstat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stats = op.lenstat(input_data=df, oligo_length_limit=170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding neutral motifs, spacers, and finalizing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last element in our oligo is an `AatII` restriction site, and we want to add 3 to 17 bases of filler next to it. We can do this using the `spacer` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But suppose we wanted to add a fixed length spacer site based on a degenerate sequence constraint, such as a motif? We would use the `motif` module instead. One way to think about this is that spacers are a more general form of motifs -- motifs are more constrained in terms of sequence composition and are of fixed length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important use of the `motif` module is in designing constant barcode anchors that is distinct from the remainder of the oligos (controlled via `maximum_repeat_length` parameter) to facilate downstream counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.motif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see this function in action by first removing the `AatII` motif column and replacing it with a degenerate motif containing the constant restriction site embedded in it but with 3 `'N'`s on its right flank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['AatII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = op.motif(\n",
    "    input_data=df,\n",
    "    oligo_length_limit=170,\n",
    "    motif_sequence_constraint='GACGTC'+'NNN', # The AatII motif with right flanking Ns\n",
    "    maximum_repeat_length=6,\n",
    "    motif_column='AatIIPadded',\n",
    "    left_context_column='YellowReversePrimer',\n",
    "    right_context_column=None,\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'])  # Exclude EcoRI, AatII, BsaI motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 in the `motif` pipeline warned us about the presence of `'GACGTC'` in our constraint itself. Nevertheless, the design step was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stats = op.lenstat(input_data=df, oligo_length_limit=170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `spacer` module to pad the oligos to 170 bases. Free space available is between 0 to 14 bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.spacer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Oligopool Calculator` can flexibly design our variable length spacers. Here our aim is to add a spacer so that the final oligo length is 170 bases, and we can achieve this by simply specifying the `oligo_length_limit` and using `None` as our `spacer_length` argument. Otherwise, we could specify the length of each spacer, in order, per oligo in a list or a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = op.spacer(\n",
    "    input_data=df,\n",
    "    oligo_length_limit=170,\n",
    "    spacer_length=None,    # Using None, we will automatically add spacers to match oligo_length_limit\n",
    "    maximum_repeat_length=6,\n",
    "    spacer_column='Spacer',\n",
    "    left_context_column='AatIIPadded',\n",
    "    right_context_column=None,\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'],  # Exclude EcoRI, AatII, BsaI motifs\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stats = op.lenstat(input_data=df, oligo_length_limit=170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our library is complete, all elements have been added, and the oligos are all 170 bases. Let's finalize our library using the `final` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? op.final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, _ = op.final(input_data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note** All annotations of the individual oligos are lost in this step. So, we saved it to a new DataFrame. In general, it is a good idea to store the result of each step in `Design Mode` to separate DataFrame variables if we were designing our pools interactively, and wanted to roll back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `final` module produces a DataFrame that needs to be passed along for synthesis. `Design Mode` functions should no longer be applied on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before shipping the library for synthesis, it is useful to run a quick QC pass. Compared to `lenstat`, the `verify` module is broader: it summarizes the architecture and length distribution, inspects column types (sequence vs metadata), and checks that excluded motifs did not re-emerge beyond their intended occurrence.\n",
    "\n",
    "It also flags degenerate/IUPAC sequence columns (e.g., UMIs) so you can confirm they are intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_stats = op.verify(\n",
    "    input_data=final_df,\n",
    "    oligo_length_limit=170,\n",
    "    excluded_motifs=['GAATTC', 'GACGTC', 'GGTCTC', 'GAGACC'],  # Exclude EcoRI, AatII, BsaI motifs\n",
    "    verbose=False)\n",
    "verify_stats['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explicitly check for any violation of our motif constraints. For example, in all our designed oligos there should only be single occurrences of the `EcoRI` and `AatII` motifs at their respective location, and no occurrences of the `BsaI` motif (since it will be used for pad excision later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert final_df.CompleteOligo.transform(lambda x: x.count('GAATTC')).values.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert final_df.CompleteOligo.transform(lambda x: x.count('GACGTC')).values.max() == 1\n",
    "assert final_df.CompleteOligo.transform(lambda x: x.count('GGTCTC')).values.max() == 0  # No BsaI sites\n",
    "assert final_df.CompleteOligo.transform(lambda x: x.count('GAGACC')).values.max() == 0  # No BsaI RC sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and padding oligos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the oligos may be longer than can be synthesized. One way to solve this problem is to use the `split` module to split such long oligos into shorter overlapping fragments. Individual sets of fragments can be padded appropriately using the `pad` module for downstream assembly. Treat each `SplitN` column as a separate synthesis pool: run `pad` once per split column, then `final` each padded DataFrame (don't run `final` on the raw multi-column `split` output). If you prefer one DataFrame per fragment, enable `separate_outputs` (CLI `op split` writes separate files by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Splitting and Padding](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/assembly.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pretend that our 170 bp oligos from above are slightly longer than can be synthesized successfully in a pool where each oligo can be at most 150 bp long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal then is to fragment the oligos so that each fragment is at most 110 bases with 40 to 60 base overlap across the fragments. We will leave 40 bases, 20 bp each for the two terminal padding primers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df, _ = op.split(\n",
    "    input_data=df,          # Notice, we are not using the \"final_df\"\n",
    "    split_length_limit=110, # Each split must be at most 110 bases long\n",
    "    minimum_melting_temperature=55, # Assembly Tm is 55°C\n",
    "    minimum_hamming_distance=5,     # Ensure the overlaps are distinct\n",
    "    minimum_overlap_length=40,    # At least 40 bp overlap\n",
    "    maximum_overlap_length=60)    # At most 60 bp overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stats = op.lenstat(input_data=split_df, oligo_length_limit=150);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have automatically split our library for two-fragment assembly. The first pool contains 110 bp oligos while the oligos in the second pool are shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split fragments are in PCR assembly order, meaning the first fragment and the second fragments are returned in opposite strands, so that PCR generates the correct full-length double-stranded oligos. We can verify this using the `revcomp` module to change the orientation of `'Split2'` column and see that the ends of `'Split1'` sequences overlap with the beginning of the sequences in `'Split2'` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip (not demoed):** Use `merge` to collapse a column range into a single DNA element before other operations.\n",
    "\n",
    "This is helpful when a multi-column region (e.g., `ForwardPrimer` + `BC1` + `Variant` + `BC2`) should be treated as one contiguous sequence for downstream steps like `revcomp` or `final`.\n",
    "\n",
    "Learn more: run `help(op.merge)` (or `? op.merge`) in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(op.revcomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df, _ = op.revcomp(\n",
    "    input_data=split_df,\n",
    "    left_context_column='Split2',\n",
    "    right_context_column='Split2',\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split1 = check_df.head(1).Split1.values[0]\n",
    "split2 = check_df.head(1).Split2.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max(len(split1), len(split2)), 0, -1):\n",
    "    if split1[-i:] == split2[:i]:\n",
    "        alignment_padding = len(split1) - i\n",
    "        print(split1)\n",
    "        print(' ' * alignment_padding + '|' * i)\n",
    "        print(' ' * alignment_padding + split2)\n",
    "        break\n",
    "else:\n",
    "    print('No overlap between computed splits!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pad` module allows designing of padded primers with embedded Type IIS restriction sites to amplify the oligo fragments, convert them to double-stranded DNA (assuming synthesized oligos are ssDNA) and enable scarless assembly downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will design our pads with `'BsaI'`, as an example. Note that we excluded the BsaI recognition motif (`GGTCTC` and its reverse complement `GAGACC`) from all earlier design elements (primers, barcodes, motifs, spacers) to ensure the Type IIS enzyme only cuts at the designed pad excision sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pad_df, _ = op.pad(\n",
    "    input_data=split_df,\n",
    "    oligo_length_limit=150, # Recall, we are pretending 150 bp synthesis limit\n",
    "    split_column='Split1',  # We will pad the first fragment\n",
    "    typeIIS_system='BsaI',  # Pad with internal 3' BsaI motif\n",
    "    minimum_melting_temperature=53,\n",
    "    maximum_melting_temperature=55,\n",
    "    maximum_repeat_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.lenstat(input_data=first_pad_df, oligo_length_limit=150);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. On to the second padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pad_df, _ = op.pad(\n",
    "    input_data=split_df,\n",
    "    oligo_length_limit=150,\n",
    "    split_column='Split2',  # We will pad the second fragment now\n",
    "    typeIIS_system='BsaI',\n",
    "    minimum_melting_temperature=53,\n",
    "    maximum_melting_temperature=55,\n",
    "    maximum_repeat_length=10,\n",
    "    verbose=False)  # Silent Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pad_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.lenstat(input_data=second_pad_df, oligo_length_limit=150);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now finalize both the padded DataFrames and ship it to our provider for synthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our `Oligopool Calculator` `Design Mode` walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Mode Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following ribozyme system architecture again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ribozyme Library Architecture](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/architecture-ribozyme.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our `Design Mode` walkthrough we designed a pool of over 6,000 simulated ribozyme variants. One characterization approach may involve sequencing an amplicon spanning `OrangeForwardPrimer` to `YellowReversePrimer` for uncleaved products, while a second sequencing of cleaved products spans `PinkForwardPrimer` through `YellowReversePrimer`. The ratio of cleaved to uncleaved products would give us the cleavage rate quntification for a ribozyme variant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Oligopool Calculator` `Analysis Mode` provides efficient tools to analyze barcoded read counts to faciliate this step, in the form of `index`, `pack`, `acount` and `xcount` modules. In this section we will explore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing the barcodes and associated variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to `index` the barcodes and associated variants to train a `Scry` barcode classifier for dowsntream counting. This step is analogous to indexing reference genomes that short-read aligners require before mapping NGS reads for genomic analysis, except our `Analysis Mode` functions are optimized for counting and therefore very sensitive, and efficient for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Indexing Reads](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/index.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althrough not explored here, you can learn more about using `Scry` via `help(op.Scry)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration, we will load an annotated oligopool we generated in the previous section from which we simulated a naive ribozyme cleavage experiment. The notebooks, reference CSV, and the simulated NGS reads are all located in our `analysis-pipeline` directory inside `examples`. The simulation parameters, in particular, can be adjusted in `read_simulator.ipynb` to test `Analysis Mode` functions with different characterization profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('analysis-pipeline/ribozyme_architecture.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now index the two barcode sets, since indexing requires us to index them individually. For BC2 in particular, we will associate the core variants for association counting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo, remove any previous indexes\n",
    "! rm -f BC*.oligopool.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = op.index(\n",
    "    barcode_data=df,\n",
    "    barcode_column='BC1',                        # Index BC1 only\n",
    "    barcode_prefix_column='OrangeForwardPrimer', # which should be next to OrangeForwardPrimer\n",
    "    barcode_suffix_column=None,                  # We have no flanking right constant for BC1\n",
    "    barcode_prefix_gap=0,\n",
    "    barcode_suffix_gap=0,\n",
    "    index_file='BC1',                            # Store results in BC1.oligopool.index file\n",
    "    verbose=False,       # Silent Mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = op.index(\n",
    "    barcode_data=df,\n",
    "    barcode_column='BC2',                        # Index BC2 only\n",
    "    barcode_prefix_column='PinkForwardPrimer',   # which should be next to OrangeForwardPrimer\n",
    "    barcode_suffix_column='YellowReversePrimer', # We have YellowReversePrimer as flanking right constant for BC2\n",
    "    barcode_prefix_gap=0,\n",
    "    barcode_suffix_gap=0,\n",
    "    associate_data=df,                           # Associates are in same DataFrame\n",
    "    associate_column='Variant',\n",
    "    associate_prefix_column=None,\n",
    "    associate_suffix_column='PinkForwardPrimer',\n",
    "    index_file='BC2',                            # Store results in BC2.oligopool.index file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note** Without specifying the associated variants for a barcode set, the resulting index cannot be used for association counting. Here, the `BC1` index can only be used for combinatorial counting, while `BC2` can be used for both association and combinatorial counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our barcodes and their associates are indexed. Let us now pack the NGS reads for counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packing the NGS reads for quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGS analysis begins with quality control of reads. Only high quality reads should be used for characterization. The `pack` module allows us to filter low quality or incorrect reads so that our quantifcation downstream is accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, if the reads are paired-end and long enough, compared to the synthesized oligo, the two mates may need to be merged into a consensus fragment, which can be done within the packing step. Alternatively, efficient tools such as [`flash2`](https://github.com/dstreett/FLASH2) can be used for the same -- merge your reads with `flash2` and use the resulting single-end reads in `pack`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, due to the nature of MPRA characterization, there may be an abundance of truly duplicate reads which `pack` module consolidates into read packs for efficient and parallel counting downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you may wish to add [unique molecular indexes](https://www.illumina.com/techniques/sequencing/ngs-library-prep/multiplexing/unique-molecular-identifiers.html) (UMIs) during your library preparation to remove spurious PCR or optical duplicates. We recommend directly processing your reads with tools such as [`calib`](https://github.com/vpc-ccg/calib) to consolidate these UMI duplicates, prior to packing and counting them using `Oligopool Calculator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Packing Reads](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/pack.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous pack, if it exists\n",
    "! rm -f NGS.oligopool.pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = op.pack(\n",
    "    r1_fastq_file='analysis-pipeline/ribozyme_1M_R1.fq.gz',\n",
    "    r2_fastq_file='analysis-pipeline/ribozyme_1M_R2.fq.gz',\n",
    "    r1_read_type='forward',     # R1 is in Forward Orientation\n",
    "    r2_read_type='reverse',     # R2 is in Reverse Orientation\n",
    "    minimum_r1_read_quality=30, # Filter out any reads with Phred Score less than 30\n",
    "    minimum_r2_read_quality=30,\n",
    "    minimum_r1_read_length=10,  # Filter out any reads shorter than 10 bases\n",
    "    minimum_r2_read_length=10,\n",
    "    pack_type='merge',          # R1 and R2 needs to be merged\n",
    "    pack_size=0.1, # Store 100K reads per read pack\n",
    "    pack_file='NGS',\n",
    "    core_count=4,  # Use only 4 CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our reads are packed and we are ready to count the barcodes. We can see that all reads \"survived\" our filters and were merged successfully. Despite sequencing a million reads, we only need to analyze less than 20 thousand reads in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of counting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the analysis pipeline utilizes packed reads and indexed barcode/variant information to generate a read count matrix, which is essential for tabulating variant activity levels. `Oligopool Calculator` `Analysis Mode` offers two efficient counting functions tailored to experimental needs: association counting and combinatorial counting. Users can define parameters for error tolerance and mapping strategy, and they have the option to specify custom callback functions that execute concurrently with the mapping and counting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Counting Reads](https://raw.githubusercontent.com/ayaanhossain/repfmt/refs/heads/main/oligopool/img/count.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Association counting of variants and barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In association counting, the goal is to verify the presence of designed variants uniquely assigned to specific barcodes. This function is useful for confirming oligopool synthesis as an initial check before cloning, or for quantifying input library distribution, or validating the association between barcodes and variants after modifications, such as replacing a spacer with a reporter protein and verifying the association across the terminal ends. The process involves mapping the core barcode after realigning the read with respect to associate prefix or suffix constants, and verifying the presence of the extracted variant subsequence against the full reference variant sequence. Reads are discarded if associate constants are missing or if the core variant has too many errors and thus cannot be verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.acount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous AC output, if it exists\n",
    "! rm -f AC.oligopool.acount.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the association of our ribozyme pool based on BC2 index (BC1 index is not usable here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_df, _ = op.acount(\n",
    "    index_file='BC2.oligopool.index', # Map BC2\n",
    "    pack_file='NGS.oligopool.pack',   # in our reads\n",
    "    count_file='AC',\n",
    "    mapping_type='sensitive', # Use sensitive/slow classification\n",
    "    barcode_errors=-1,   # Use model-based auto-inferred error tolerance\n",
    "    associate_errors=-1,\n",
    "    callback=None,\n",
    "    core_count=0,\n",
    "    memory_limit=0.0,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the reads were mis-associated, as in everytime we detected a barcode, its associated variant was also found to be present in the read within error tolerance. This is of course artificial in our simulated example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our counts! The `BarcodeCounts` column shows the number of times the barcode was detected in a read, while `AssociationCounts` shows the number of times the barcode was unambiguously present with its designated associated variant.\n",
    "\n",
    "In this simulated case, all reads are error-free, so `AssociationCounts` is the same as `BarcodeCounts`. In real-life scenarios, we expect `AssociationCounts` to be ≤ `BarcodeCounts` because not all barcoded reads retain an intact associate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the ranks of the designs and make some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_df['variant_rank'] = ac_df['BC2.ID'].transform(lambda x: int(x.split('_')[-1]))\n",
    "ac_df['variant_rank_bin'] = ac_df.variant_rank.transform(lambda x: x//1000)\n",
    "ac_df['variant_norm_read_count'] = (ac_df.BarcodeCounts - ac_df.BarcodeCounts.mean()) / ac_df.BarcodeCounts.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(16,7))\n",
    "sns.scatterplot(\n",
    "    data=ac_df,\n",
    "    x='variant_rank', y='BarcodeCounts',\n",
    "    hue='variant_rank_bin',\n",
    "    palette='Paired',\n",
    "    s=5, ec=None,\n",
    "    ax=ax[0]).set(\n",
    "        ylabel='read_count')\n",
    "sns.boxplot(\n",
    "    data=ac_df,\n",
    "    x='variant_norm_read_count',\n",
    "    fill=False, notch=True, linewidth=1,\n",
    "    hue='variant_rank_bin',\n",
    "    palette='Paired',\n",
    "    ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As simulated, the higher the rank of the variant, the more frequently it appeared. In real experimental data, if the pool being sequenced has not undergone selection (say input library) then we expect this distribution to be uniform across all variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinatorial barcode counting with callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinatorial counting is employed when a single or multiple barcode combinations are expected within sequenced reads. `xcount` uses multiple indexes to map the barcodes independently, allowing for flexibility in experimental design. Reads are only discarded if none of the expected barcodes are present, meaning that one or more missing barcodes are tolerated. This approach can accommodate isolated barcodes with their own flanking constants or unique combinations of sub-sequences within a larger assembly through combinatorial methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? op.xcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply combinatorial counting using both BC1 and BC2 index here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous CC output, if it exists\n",
    "! rm -f CC.oligopool.xcount.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df, _ = op.xcount(\n",
    "    index_files=['BC1', 'BC2'],     # Map combinations of BC1 and BC2\n",
    "    pack_file='NGS.oligopool.pack',\n",
    "    count_file='CC',\n",
    "    mapping_type='sensitive',       # Use sensitive/slow classification\n",
    "    barcode_errors=-1,\n",
    "    callback=None,\n",
    "    core_count=0,\n",
    "    memory_limit=0.0,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have counts of either BC2 or both BC1 and BC2 barcodes from our reads, signifying cleaved and ucleaved products respectively. We can now use this count matrix to compute the activity of the ribozymes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df['ID'] = cc_df['BC2.ID']\n",
    "cc_df['count_basis'] = cc_df.apply(lambda x: 'cleaved_reads' if x['BC1.ID'] != x['BC2.ID'] else 'uncleaved_reads', axis=1)\n",
    "act_df = cc_df.pivot(index='ID', columns='count_basis', values='CombinatorialCounts').fillna(0.).reset_index()\n",
    "act_df['activity'] = act_df.apply(lambda x: 100. * x.cleaved_reads / (x.cleaved_reads + x.uncleaved_reads), axis=1)\n",
    "act_df = act_df.merge(ac_df, left_on='ID', right_on='BC2.ID').drop(columns=['BC2.ID']).rename(columns={'BarcodeCounts': 'input_reads'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(16,7))\n",
    "sns.scatterplot(\n",
    "    data=act_df,\n",
    "    x='input_reads', y='activity',\n",
    "    hue='variant_rank_bin',\n",
    "    palette='Paired',\n",
    "    s=5, ec=None,\n",
    "    ax=ax[0])\n",
    "sns.scatterplot(\n",
    "    data=act_df,\n",
    "    x='cleaved_reads', y='uncleaved_reads',\n",
    "    hue='activity',\n",
    "    palette='viridis',\n",
    "    s=5, ec=None,\n",
    "    ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As simulated, the higher the rank of the variant the more input reads it had, which is proportional to the inferred activity. This is seen in the plot on the left. The right plot shows those high activity variants having a larger proportion of cleaved reads relative to their uncleaved read counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us use a callback function to filter out any reads not matching our simulated criteria of the cleavage location being the 10th base of the variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we will observe a couple of things. First, the cleaved reads will only contain BC2 in them. Second, the subsequence specified in the `Variant` column will appear partially in the read. Infact as simulated, the cleaved reads will contain part of the variant, the whole of `PinkForwardPrimer` and `BC2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `xcount` and `acount` allows us to use the information from the reads to concurrently do our own calculations on the reads and to signal to the counting algorithm whether to use the read as part of the counting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous CC output, if it exists\n",
    "! rm -f CCC.oligopool.xcount.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a shared dictionary for our callback below (detailed later)\n",
    "ribozyme_memory = Manager().dict(zip(df.ID, df.Variant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback logic\n",
    "def filter_non_cleaved_reads(ribozyme_memory, pink_forward_primer):\n",
    "    '''Outer wrapper to give our method some memory.'''\n",
    "\n",
    "    def wrapped(read, ID, count, coreid):\n",
    "        '''Inner closure to filter reads.\n",
    "\n",
    "        Note that `xcount` and `acount` callbacks must have this signature.\n",
    "        See help(op.acount) or help(op.xcount) for details.'''\n",
    "\n",
    "        # If more than one barcode present, we are not going to do anything with it, because\n",
    "        # it implies an uncleaved read. We only want to use BC2-exclusive cleaved reads.\n",
    "        if ID[0] is None and not ID[1] is None:\n",
    "            # The first ID will be None during `xcount` because we will compute BC1 x BC2\n",
    "\n",
    "            # Extract ribozyme ID\n",
    "            ribozyme_id = ID[1]\n",
    "\n",
    "            # The constant primer must be present for acceptance\n",
    "            if pink_forward_primer in read:\n",
    "\n",
    "                # Extract ribozyme fragment\n",
    "                ribozyme_fragment = read[:read.index(pink_forward_primer)]\n",
    "                # Fetch the expected full variant\n",
    "                ribozyme_full = ribozyme_memory[ribozyme_id]\n",
    "\n",
    "                # Figure out where the fragment starts in the variant\n",
    "                if ribozyme_fragment in ribozyme_full:\n",
    "                    ribozyme_start = ribozyme_full.index(ribozyme_fragment)\n",
    "                    # This index must be 10 or greater for cleaved product-based read\n",
    "                    return ribozyme_start >= 10\n",
    "\n",
    "            '''\n",
    "            Note: Here we are using exact matching logic. In reality we might want to do\n",
    "                  some alignment based extraction of our fragments to be error-aware.\n",
    "            '''\n",
    "\n",
    "        # Reject the read for counting ... didn't pass filtering due to one or more reasons\n",
    "        return False\n",
    "\n",
    "    # Return Wrapped Processor\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtually any logic can be executed concurrently with counting, as long as the callback returns a boolean. If a callback function returns `False`, the counting function will not use the reads for counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to, we can also record additional results from our callback calculations via [shared data structures](https://superfastpython.com/multiprocessing-manager-example/) such as a `Manager` `dict` or `list`. This is useful, for example, if we wanted to extract and store the location of cleavage sites in reads (instead of assuming it to be the 10th base in the designed variants). Another similar use case is extracting transcription start sites for a library of designed promoters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note** The `Manager` `dict` here ensures that all parallel callback processes during counting will have access to the same exact dictionary, controlled and synchronized by a separate `Manager` instance. This allows us to modify the content of the managed dictionary in one process and have the changes be reflected in callbacks executed by other counting processes in parallel. This also allows us to easily gather and store additional results, in parallel, to a persistent and centralized dictionary for post-counting analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that we need to use the outer wrapper as callback\n",
    "cc_callback = filter_non_cleaved_reads(\n",
    "    ribozyme_memory=ribozyme_memory,\n",
    "    pink_forward_primer=df.PinkForwardPrimer.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry, if our callback fails, the return stats dictionary will contain the inputs for which our callback failed and we can debug accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, stats = op.xcount(\n",
    "    index_files=['BC1', 'BC2'],\n",
    "    pack_file='NGS.oligopool.pack',\n",
    "    count_file='CCC',\n",
    "    mapping_type='sensitive',       # Use sensitive/slow classification\n",
    "    barcode_errors=-1,\n",
    "    callback=cc_callback,\n",
    "    core_count=0,\n",
    "    memory_limit=0.0,\n",
    "    verbose=False) # Silent Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our callback filtering function rejected a lot of reads, as recorded in `callback_false_reads` key in the stats dictionary. Rest of the reads were cleaved and were accepted for counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That concludes our `Analysis Mode` walkthrough! Let us remove all the `Analysis Mode` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -f BC*.oligopool.index NGS.oligopool.pack AC.oligopool.acount.csv CC*.oligopool.xcount.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Oligopool Calculator` offers a comprehensive solution for designing and analyzing genetic part libraries using oligopools. Its `Design Mode` automates the creation of oligopool architectures for various genetic elements, enabling synthetic biologists to efficiently compose and assemble complex libraries. The `Analysis Mode` provides flexible, barcode-based counting of NGS reads for variant characterization, with options for custom analysis. We hope this tool empowers researchers to fully leverage oligopools in engineering and screening large libraries of functional genetic parts, facilitating the development of accurate models of part function. It is designed to streamline the entire process from design to analysis, and we hope it will be a useful resource for synthetic biology research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlde-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
